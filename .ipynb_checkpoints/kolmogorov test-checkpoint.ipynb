{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "이를 수행하는 두 가지 방법은 QQ 플롯 과 Kolmogorov-Smirnov 테스트입니다.\n",
    "\n",
    "두 분포의 차이를 결정하고 정량화하는 프로그래밍 방식을 찾고 있으므로 KS 테스트를 권장합니다. KS 테스트는 테스트에서 p- 값을 쉽게 얻을 수 있고 실행하기가 매우 쉽다는 점에서 좋습니다. 다음은 Python 코드의 예입니다.\n",
    "\n",
    "\n",
    "You can compare distribution of the two columns using two-sample Kolmogorov-Smirnov test, it is included in the scipy.stats: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ks_2samp.html\n",
    "\n",
    "From the stackoverflow topic:\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(123456)\n",
    "x = np.random.normal(0, 1, 1000)\n",
    "y = np.random.normal(0, 1, 1000)\n",
    "z = np.random.normal(1.1, 0.9, 1000)\n",
    "\n",
    ">>> ks_2samp(x, y)\n",
    "Ks_2sampResult(statistic=0.022999999999999909, pvalue=0.95189016804849647)\n",
    ">>> ks_2samp(x, z)\n",
    "Ks_2sampResult(statistic=0.41800000000000004, pvalue=3.7081494119242173e-77)\n",
    "Under the null hypothesis the two distributions are identical. If the K-S statistic is small or the p-value is high (greater than the significance level, say 5%), then we cannot reject the hypothesis that the distributions of the two samples are the same. Conversely, we can reject the null hypothesis if the p-value is low.\n",
    "\"\"\"\n",
    "import scipy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "left = np.array([2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
    "4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
    "6, 6,6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7])\n",
    "\n",
    "right = np.array([2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7])\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "x = np.random.normal(0,1,1000)\n",
    "y = np.random.normal(0,1,1000)\n",
    "ks_2samp(x, y)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KstestResult(statistic=0.1710189452124936, pvalue=0.4100192837257659)\n"
     ]
    }
   ],
   "source": [
    "print(ks_2samp(left,right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "카이제곱 검정\n",
    "정규화의 과정이 필요할 할 것\n",
    "\n",
    "10\n",
    "\n",
    "Kolmogorov-Smirnov 테스트를 찾고 있습니다. 막대 높이를 각 히스토그램의 모든 관측 값의 합으로 나누는 것을 잊지 마십시오.\n",
    "\n",
    "예를 들어 분포의 평균이 서로에 대해 상대적으로 이동하는 경우 KS 테스트는 차이를보고합니다. x 축을 따라 히스토그램을 변환하는 것이 응용 프로그램에서 의미가없는 경우 먼저 각 히스토그램에서 평균을 뺄 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydatavenv",
   "language": "python",
   "name": "pydatavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
